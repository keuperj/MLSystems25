{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keuperj/MLSystems25/blob/main/week_2/Aufgabe_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1 - Matrix multiplication in Numba\n",
        "\n",
        "\n",
        "We consider the problem of evaluating the matrix multiplication $C = A\\times B$ for matrices $A, B\\in\\mathbb{R}^{n\\times n}$.\n",
        "A simple Python implementation of the matrix-matrix product is given below through the function `matrix_product`. At the end this\n",
        "function is checked against the Numpy implementation of the matrix-matrix product."
      ],
      "metadata": {
        "id": "aoWE7qo6G7wu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import numpy as np\n",
        "\n",
        "def matrix_product(mat_a, mat_b):\n",
        "    \"\"\"Returns the product of the matrices mat_a and mat_b.\"\"\"\n",
        "    m = mat_a.shape[0]\n",
        "    n = mat_b.shape[1]\n",
        "\n",
        "    assert(mat_a.shape[1] == mat_b.shape[0])\n",
        "\n",
        "    ncol = mat_a.shape[1]\n",
        "\n",
        "    mat_c = np.zeros((m, n), dtype=np.float64)\n",
        "\n",
        "    for row_ind in range(m):\n",
        "        for col_ind in range(n):\n",
        "            for k in range(ncol):\n",
        "                mat_c[row_ind, col_ind] += mat_a[row_ind, k] * mat_b[k, col_ind]\n",
        "\n",
        "    return mat_c\n",
        "\n",
        "a = np.random.randn(10, 10)\n",
        "b = np.random.randn(10, 10)\n",
        "\n",
        "c_actual = matrix_product(a, b)\n",
        "c_expected = a @ b\n",
        "\n",
        "error = np.linalg.norm(c_actual - c_expected) / np.linalg.norm(c_expected)\n",
        "print(f\"The error is {error}.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The error is 9.838746068650953e-17.\n"
          ]
        }
      ],
      "metadata": {
        "id": "EykKUagzG7wy",
        "outputId": "0c72efeb-2d94-44b8-c5e7-68057bcdb0c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The matrix product is one of the most fundamental operations on modern computers. Most algorithms eventually make use of this operation. A lot of effort is therefore spent on optimising the matrix product. Vendors provide hardware optimised BLAS (Basis Linear Algebra Subroutines) that provide highly efficient versions of the matrix product. Alternatively, open-source libraries sucha as Openblas provide widely used generic open-source implementations of this operation.\n",
        "\n",
        "In this assignment we want to learn at the example of matrix-matrix products about the possible speedups offered by Numba, and the effects of cache-efficient programming.\n",
        "\n",
        "## 1.1 Benchmark\n",
        "Benchmark the above function against the Numpy dot product for matrix sizes up to 1000. Plot the timing results of the above function against the timing results for the Numpy dot product. You need not benchmark every dimension up to 1000. Figure out what dimensions to use so that you can represent the result without spending too much time waiting for the code to finish. To perform benchmarks you can use the `%timeit` magic command. An example is\n",
        "\n",
        "    ```\n",
        "    timeit_result = %timeit -o matrix_product(a, b)\n",
        "    print(timeit_result.best)\n",
        "    ```\n",
        "\n",
        "## 1.2 Optimize\n",
        "Now optimise the code by using Numba to JIT-compile it. Also, there is lots of scope for parallelisation in the code. You can for example parallelize the outer-most for-loop. Benchmark the JIT-compiled serial code against the JIT-compiled parallel code. Comment on the expected performance on your system against the observed performance.\n",
        "\n",
        "## 1.3 (Optional) Cache Optimization\n",
        "Now let us improve Cache efficiency. Notice that in the matrix $B$ we traverse by columns. However, the default storage ordering in Numpy is row-based. Hence, the expression `mat_b[k, col_ind]` jumps in memory by `n` units if we move from $k$ to $k+1$. Run your parallelized JIT-compiled Numba code again. But this time choose a matrix $B$ that is stored in column-major order. To change an array to column major order you can use the command `np.asfortranarray`.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oji80g9mG7w1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8swjgJwpG7w2"
      }
    }
  ],
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit ('dev': conda)"
    },
    "interpreter": {
      "hash": "433c521acb4ce4629f0708f9192dd3599e20d0bdeb40353d5f8d17c68a66b248"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}